{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Enoncé_Projet_ChatsChiens_Etape2_AugmentationDeDonnee.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uluumy/Fondements-de-l-apprentissage-profond/blob/master/Enonc%C3%A9_Projet_ChatsChiens_Etape2_AugmentationDeDonnee.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjn5b6oaE8Qf",
        "colab_type": "text"
      },
      "source": [
        "# Projet: Chats vs Chiens\n",
        "## Classification d'images: avec augmentation de donnees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsiTasbkUvKY",
        "colab_type": "text"
      },
      "source": [
        "##Étape 1: Mise en place de l'environnement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOW8FWm-VbWE",
        "colab_type": "text"
      },
      "source": [
        "### Colab\n",
        "\n",
        "Execution -> Reinitialiser tous les environnemetns d'execussion (lRuntime -> Reset all runtimes)\n",
        "\n",
        "Execussion -> Modifier le type d'execussion -> Accelereateur materiel -> GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMqwzSZ3Vfbu",
        "colab_type": "text"
      },
      "source": [
        "### Librairies à importer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZJHWoRlFJpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbt5sQb5ZYY-",
        "colab_type": "text"
      },
      "source": [
        "### Fonctions utiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYdhEuV2Zb3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(x,y1,y2,y1_label, y2_label, x_label, y_label,title):\n",
        "  plt.clf()\n",
        "  plt.plot(x, y1, label=y1_label) \n",
        "  plt.plot(x, y2, label=y2_label)\n",
        "  \n",
        "  plt.title(title)\n",
        "  plt.xlabel(x_label)\n",
        "  plt.ylabel(y_label)\n",
        "  plt.legend()\n",
        "  plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0MN5l_iz8im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cette fonction affiche l'image.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM4w06rcW33F",
        "colab_type": "text"
      },
      "source": [
        "## Étape 2: Obtention des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fG00Xc4wH9Z",
        "colab_type": "text"
      },
      "source": [
        "### Importer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrtP0BGSWyud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeYAzvJZW41k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip_dir_base = os.path.dirname(zip_dir)\n",
        "!find $zip_dir_base -type d -print"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni6PXGuzwy9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mT_3CnlwRnJ",
        "colab_type": "text"
      },
      "source": [
        "###Comprendre les données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jFDxBomwd2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEy2HFBaxDs8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66j6DVNWxwA_",
        "colab_type": "text"
      },
      "source": [
        "### Mise en place des paramétres du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5iz08GBxuA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 256  # Number of training examples to process before updating our models variables\n",
        "IMG_SHAPE  = 150  # Our training data consists of images with width of 150 pixels and height of 150 pixels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYgGBnYryFTJ",
        "colab_type": "text"
      },
      "source": [
        "## Étape 3: Augmentation des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlHeyU_PgnAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ImageAgmentation(datagen,imageIndex):\n",
        "  from keras.preprocessing import image\n",
        "\n",
        "  fnames = [os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)]\n",
        "\n",
        "  # on choisit une image à \"augmenter\"\n",
        "  img_path = fnames[imageIndex]\n",
        "\n",
        "  # Lire lèimage et la redimensionner\n",
        "  img = image.load_img(img_path, target_size=(150, 150))\n",
        "\n",
        "  # la convertir en Numpy array avec shape (150, 150, 3)\n",
        "  x = image.img_to_array(img)\n",
        "\n",
        "  # Reshape avec (1, 150, 150, 3)\n",
        "  x = x.reshape((1,) + x.shape)\n",
        "\n",
        "  # The .flow() command below generates batches of randomly transformed images.\n",
        "  # It will loop indefinitely, so we need to `break` the loop at some point!\n",
        "  i = 0\n",
        "  for batch in datagen.flow(x, batch_size=1):\n",
        "      plt.figure(i)\n",
        "      imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "      i += 1\n",
        "      if i % 2 == 0:\n",
        "          break\n",
        " \n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV6qbK-qcVhP",
        "colab_type": "text"
      },
      "source": [
        "### Retourner l'image horizontalement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuyaK-j3zMcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "      horizontal_flip=True\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOylIUl9dNTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ImageAgmentation(datagen,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkVucDT1jfy9",
        "colab_type": "text"
      },
      "source": [
        "### --- TODO--- Rotation de l'image\n",
        "appler la fonction ImageDataGenerator pour effectuer une rotation de 20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dFgNz7JjmLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = # TODO \n",
        "\n",
        "ImageAgmentation(datagen,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzofSXA_jk0-",
        "colab_type": "text"
      },
      "source": [
        "### Application de zoom "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXeVpmICj--H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "      zoom_range=0.5,\n",
        "     )\n",
        "ImageAgmentation(datagen,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4HbgCF0kOUC",
        "colab_type": "text"
      },
      "source": [
        "### Appliquer plusieurs transforamtions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kdh1p0bLkWcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "ImageAgmentation(datagen,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNsRWia9m0cC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O-m1NjKz2ZP",
        "colab_type": "text"
      },
      "source": [
        "### Generation des des donnees d'entrainement avec augmentation des donnees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa0Eqebq0AKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE, \n",
        "                                                     directory=train_dir, \n",
        "                                                     shuffle=True, \n",
        "                                                     target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                     class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlJIzNxFnEEh",
        "colab_type": "text"
      },
      "source": [
        "### Donnees de validation (sans augmentation des donnees)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av5lreCPnJQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE, \n",
        "                                                 directory=validation_dir, \n",
        "                                                 target_size=(IMG_SHAPE, IMG_SHAPE),\n",
        "                                                 class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPX7xWoj2X8a",
        "colab_type": "text"
      },
      "source": [
        "## ---TODO--- Étape 3: Création du modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FneWdz1E5jj",
        "colab_type": "text"
      },
      "source": [
        "### ---TODO---Définir le modèle\n",
        "\n",
        "Définir un modèle séquentiel avec les couches suivantes:\n",
        "\n",
        "1) Premiere couche Conv2D avec filters = 32, kernel_size = (3,3), relu comme activation et bien choisir le parametre input_shape=(?, ?, ?) Garder les autres valeurs par défaut\n",
        "\n",
        "2) MaxPooling avec pool_size = (2,2) et garder les autres valeurs par défaut\n",
        "\n",
        "3) Couche Conv2D avec filters = 64, kernel_size = (3,3), relu comme activation\n",
        "\n",
        "4 MaxPooling avec pool_size = (2,2) et garder les autres valeurs par défaut\n",
        "\n",
        "5) Couche Conv2D avec filters = 128, kernel_size = (3,3), relu comme activation\n",
        "\n",
        "6) MaxPooling avec pool_size = (2,2) et garder les autres valeurs par défaut\n",
        "\n",
        "7) Couche Conv2D avec filters = 128, kernel_size = (3,3), relu comme activation\n",
        "\n",
        "8) MaxPooling avec pool_size = (2,2) et garder les autres valeurs par défaut\n",
        "\n",
        "9) Couche Dropout avec un rate de 0.5 et garder les autres valeurs par défaut\n",
        "\n",
        "10) Couche flatten\n",
        "\n",
        "11) Couche Dense: 512 unit et relu comme activation\n",
        "\n",
        "12) Couche dense de sortie: bien choisir le nombre d'unit et la fonction d'activation (tip: on a un problème de classification binaire)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEXp2VHY2aVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = # TODO "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjSuMbCMFNKL",
        "colab_type": "text"
      },
      "source": [
        "### Compiler le modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zBCALccFzyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKV66wFKF05F",
        "colab_type": "text"
      },
      "source": [
        "### Sommaire du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HER7oi53F3tw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73I06Ik0GAIN",
        "colab_type": "text"
      },
      "source": [
        "### Entrainer le modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDdgGwYqyoGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=20\n",
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE)))\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37JC6_hKG0MW",
        "colab_type": "text"
      },
      "source": [
        "### Visualisation des résultats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbcnNDYeZm9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "val_loss = history.history['val_loss']\n",
        "plot_history(epochs_range, acc, val_acc, 'Training accuracy', 'Validation accuracy', 'Epochs', 'Accuracy','Training and validation Accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lT1a1RwvHxh",
        "colab_type": "text"
      },
      "source": [
        "ressources\n",
        "https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l05c01_dogs_vs_cats_without_augmentation.ipynb#scrollTo=rtPGh2MAVrVa\n",
        "\n",
        "https://github.com/uluumy/deep-learning-with-python-notebooks/blob/master/5.2-using-convnets-with-small-datasets.ipynb\n",
        "\n",
        "Data Augmentation\n",
        "https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l05c02_dogs_vs_cats_with_augmentation.ipynb#scrollTo=GBYLOFgOXPJ9\n",
        "\n",
        "Transfert Learning\n",
        "https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l06c01_tensorflow_hub_and_transfer_learning.ipynb\n",
        "\n"
      ]
    }
  ]
}